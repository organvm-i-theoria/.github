#!/usr/bin/env python3
"""Advanced Deployment Automation.

Orchestrates deployment of Month 1-3 workflows with:
- Environment validation
- Phased rollout (canary ‚Üí progressive ‚Üí full)
- Health checks
- Automatic rollback on failure

Usage:
    ./deploy.py --env staging --month 1
    ./deploy.py --env production --month all --canary-repos "org/repo1,org/repo2"
    ./deploy.py --rollback --deployment-id abc123
"""

import argparse
import json
import os
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Optional

import requests
import yaml


class DeploymentOrchestrator:
    """Manages deployment lifecycle for workflow automation."""

    def __init__(self, environment: str, github_token: str):
        """Initialize deployment orchestrator.

        Args:
            environment: Target environment (staging, production)
            github_token: GitHub API token

        """
        self.environment = environment
        self.github_token = github_token
        self.api_base = "https://api.github.com"
        self.session = requests.Session()
        self.session.headers.update(
            {
                "Authorization": f"Bearer {github_token}",
                "Accept": "application/vnd.github+json",
                "X-GitHub-Api-Version": "2022-11-28",
            }
        )

        # Load environment configuration
        self.config = self._load_config()

        # Deployment tracking
        self.deployment_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.deployment_log: list[dict[str, Any]] = []

    def _load_config(self) -> dict[str, Any]:
        """Load environment-specific configuration."""
        config_path = Path("automation/deployment/environments.yml")

        if not config_path.exists():
            print(f"‚ö†Ô∏è  Config not found: {config_path}")
            return self._default_config()

        with open(config_path) as f:
            all_configs = yaml.safe_load(f)

        return all_configs.get(self.environment, self._default_config())

    def _default_config(self) -> dict[str, Any]:
        """Provide default configuration."""
        return {
            "repositories": [],
            "canary_percentage": 10,
            "progressive_percentage": 50,
            "health_check_interval": 60,
            "health_check_duration": 300,
            "rollback_threshold": 0.85,  # 85% success rate minimum
        }

    def validate_environment(self) -> bool:
        """Validate deployment environment is ready.

        Returns:
            True if environment is valid

        """
        print(f"üîç Validating {self.environment} environment...")

        checks = [
            ("GitHub token", self._check_github_token()),
            ("Repository access", self._check_repository_access()),
            ("Workflow files", self._check_workflow_files()),
            ("Secret configuration", self._check_secrets()),
        ]

        all_passed = True
        for check_name, passed in checks:
            status = "‚úÖ" if passed else "‚ùå"
            print(f"  {status} {check_name}")
            if not passed:
                all_passed = False

        if not all_passed:
            print("\n‚ùå Environment validation failed!")
            return False

        print("\n‚úÖ Environment validation passed!")
        return True

    def _check_github_token(self) -> bool:
        """Check GitHub token is valid."""
        try:
            response = self.session.get(f"{self.api_base}/user")
            return response.status_code == 200
        except Exception as e:
            print(f"    Error: {e}")
            return False

    def _check_repository_access(self) -> bool:
        """Check access to configured repositories."""
        repos = self.config.get("repositories", [])

        if not repos:
            print("    Warning: No repositories configured")
            return True

        for repo in repos[:3]:  # Check first 3
            try:
                response = self.session.get(f"{self.api_base}/repos/{repo}")
                if response.status_code != 200:
                    print(f"    Cannot access: {repo}")
                    return False
            except Exception as e:
                print(f"    Error checking {repo}: {e}")
                return False

        return True

    def _check_workflow_files(self) -> bool:
        """Check workflow files exist locally."""
        workflow_dir = Path(".github/workflows")

        if not workflow_dir.exists():
            print("    .github/workflows directory not found")
            return False

        workflows = list(workflow_dir.glob("*.yml"))
        if len(workflows) < 5:
            print(f"    Only {len(workflows)} workflows found (expected 5+)")
            return False

        return True

    def _check_secrets(self) -> bool:
        """Check required secrets are configured."""
        required_secret_names = self.config.get("required_secrets", [])

        for secret_name in required_secret_names:
            if not os.getenv(secret_name):
                print(f"    Missing secret environment variable: {secret_name}")
                return False

        return True

    def deploy_workflows(self, month: int, canary_repos: Optional[list[str]] = None) -> bool:
        """Deploy workflows with phased rollout.

        Args:
            month: Month to deploy (1, 2, 3, or 'all')
            canary_repos: List of repositories for canary deployment

        Returns:
            True if deployment succeeded

        """
        print(f"\nüöÄ Starting Month {month} deployment...")
        print(f"   Environment: {self.environment}")
        print(f"   Deployment ID: {self.deployment_id}")

        # Phase 1: Canary deployment
        if not self._canary_deployment(month, canary_repos):
            print("\n‚ùå Canary deployment failed! Aborting.")
            return False

        # Phase 2: Progressive rollout
        if not self._progressive_deployment(month):
            print("\n‚ùå Progressive deployment failed! Rolling back...")
            self.rollback()
            return False

        # Phase 3: Full deployment
        if not self._full_deployment(month):
            print("\n‚ùå Full deployment failed! Rolling back...")
            self.rollback()
            return False

        print(f"\n‚úÖ Deployment {self.deployment_id} completed successfully!")
        return True

    def _canary_deployment(self, month: int, canary_repos: Optional[list[str]]) -> bool:
        """Deploy to canary repositories."""
        print("\nüìç Phase 1: Canary Deployment")

        repos = canary_repos or self._select_canary_repos()
        print(f"   Deploying to {len(repos)} canary repositories...")

        for repo in repos:
            if not self._deploy_to_repository(repo, month):
                return False

        # Health check
        print("\n   Running health checks...")
        if not self._health_check(repos, duration=180):
            return False

        print("   ‚úÖ Canary deployment successful!")
        return True

    def _progressive_deployment(self, month: int) -> bool:
        """Deploy to progressive percentage of repositories."""
        print("\nüìä Phase 2: Progressive Rollout")

        percentage = self.config.get("progressive_percentage", 50)
        repos = self._select_progressive_repos(percentage)
        print(f"   Deploying to {len(repos)} repositories ({percentage}%)...")

        for repo in repos:
            if not self._deploy_to_repository(repo, month):
                return False

        # Health check
        print("\n   Running health checks...")
        if not self._health_check(repos, duration=240):
            return False

        print("   ‚úÖ Progressive rollout successful!")
        return True

    def _full_deployment(self, month: int) -> bool:
        """Deploy to all remaining repositories."""
        print("\nüåç Phase 3: Full Deployment")

        repos = self.config.get("repositories", [])
        remaining = [r for r in repos if not self._is_deployed(r)]
        print(f"   Deploying to {len(remaining)} remaining repositories...")

        for repo in remaining:
            if not self._deploy_to_repository(repo, month):
                return False

        # Final health check
        print("\n   Running final health checks...")
        if not self._health_check(repos, duration=300):
            return False

        print("   ‚úÖ Full deployment successful!")
        return True

    def _deploy_to_repository(self, repo: str, month: int) -> bool:
        """Deploy workflows to a single repository.

        Args:
            repo: Repository name (org/repo)
            month: Month to deploy

        Returns:
            True if deployment succeeded

        """
        print(f"      Deploying to {repo}...", end=" ")

        try:
            # Get workflow files for month
            workflows = self._get_workflows_for_month(month)

            # Deploy each workflow
            for workflow_file in workflows:
                if not self._push_workflow(repo, workflow_file):
                    print("‚ùå")
                    return False

            # Log deployment
            self.deployment_log.append(
                {
                    "repo": repo,
                    "month": month,
                    "timestamp": datetime.now().isoformat(),
                    "status": "deployed",
                }
            )

            print("‚úÖ")
            return True

        except Exception as e:
            print(f"‚ùå Error: {e}")
            return False

    def _push_workflow(self, repo: str, workflow_file: Path) -> bool:
        """Push workflow file to repository."""
        try:
            # Read workflow content
            with open(workflow_file) as f:
                content = f.read()

            # Push to repository via GitHub API
            file_path = f".github/workflows/{workflow_file.name}"

            # Check if file exists
            get_response = self.session.get(f"{self.api_base}/repos/{repo}/contents/{file_path}")

            sha = None
            if get_response.status_code == 200:
                sha = get_response.json().get("sha")

            # Create or update file
            import base64

            encoded_content = base64.b64encode(content.encode()).decode()

            data = {
                "message": f"Deploy workflow: {workflow_file.name} ({self.deployment_id})",
                "content": encoded_content,
            }

            if sha:
                data["sha"] = sha

            response = self.session.put(f"{self.api_base}/repos/{repo}/contents/{file_path}", json=data)

            return response.status_code in [200, 201]

        except Exception as e:
            print(f"\n         Error pushing workflow: {e}")
            return False

    def _health_check(self, repos: list[str], duration: int) -> bool:
        """Perform health checks on deployed repositories.

        Args:
            repos: List of repositories to check
            duration: Health check duration in seconds

        Returns:
            True if health checks passed

        """
        start_time = time.time()
        interval = self.config.get("health_check_interval", 60)

        while time.time() - start_time < duration:
            success_count = 0

            for repo in repos:
                if self._check_repository_health(repo):
                    success_count += 1

            success_rate = success_count / len(repos) if repos else 0
            threshold = self.config.get("rollback_threshold", 0.85)

            print(
                f"      Health: {success_count}/{len(repos)} ({success_rate:.1%})",
                end="\r",
            )

            if success_rate < threshold:
                print(f"\n      ‚ùå Health check failed: {success_rate:.1%} < {threshold:.1%}")
                return False

            time.sleep(interval)

        print("\n      ‚úÖ Health checks passed!")
        return True

    def _check_repository_health(self, repo: str) -> bool:
        """Check health of a single repository."""
        try:
            # Get recent workflow runs
            response = self.session.get(f"{self.api_base}/repos/{repo}/actions/runs", params={"per_page": 10})

            if response.status_code != 200:
                return False

            runs = response.json().get("workflow_runs", [])
            if not runs:
                return True  # No runs yet, consider healthy

            # Check success rate of recent runs
            successful = sum(1 for run in runs if run.get("conclusion") == "success")
            success_rate = successful / len(runs)

            return success_rate >= self.config.get("rollback_threshold", 0.85)

        except Exception:
            return False

    def _get_workflows_for_month(self, month: int) -> list[Path]:
        """Get workflow files for specific month."""
        workflow_dir = Path(".github/workflows")

        # Month 1 workflows
        month1_workflows = [
            "issue-triage.yml",
            "auto-assign.yml",
            "status-sync.yml",
            "stale-management.yml",
            "collect-metrics.yml",
        ]

        # Month 2 workflows
        month2_workflows = [
            "slack-daily-summary.yml",
            "stale-management-ab.yml",
            "email-digest.yml",
        ]

        # Month 3 workflows
        month3_workflows = [
            "auto-merge.yml",
            "self-healing.yml",
            "proactive-maintenance.yml",
            "sla-monitoring.yml",
            "incident-response.yml",
        ]

        workflow_map = {
            1: month1_workflows,
            2: month1_workflows + month2_workflows,
            3: month1_workflows + month2_workflows + month3_workflows,
        }

        workflow_names = workflow_map.get(month, [])
        return [workflow_dir / name for name in workflow_names if (workflow_dir / name).exists()]

    def _select_canary_repos(self) -> list[str]:
        """Select repositories for canary deployment."""
        repos = self.config.get("repositories", [])
        percentage = self.config.get("canary_percentage", 10)
        count = max(1, int(len(repos) * percentage / 100))
        return repos[:count]

    def _select_progressive_repos(self, percentage: int) -> list[str]:
        """Select repositories for progressive deployment."""
        repos = self.config.get("repositories", [])
        count = int(len(repos) * percentage / 100)
        return repos[:count]

    def _is_deployed(self, repo: str) -> bool:
        """Check if repository already deployed."""
        return any(log["repo"] == repo for log in self.deployment_log)

    def rollback(self) -> bool:
        """Rollback deployment to previous state.

        Returns:
            True if rollback succeeded

        """
        print(f"\n‚è™ Rolling back deployment {self.deployment_id}...")

        # Get deployed repositories from log
        deployed_repos = [log["repo"] for log in self.deployment_log]

        print(f"   Rolling back {len(deployed_repos)} repositories...")

        for repo in deployed_repos:
            print(f"      {repo}...", end=" ")
            if self._rollback_repository(repo):
                print("‚úÖ")
            else:
                print("‚ùå")

        print("\n‚úÖ Rollback complete!")
        return True

    def _rollback_repository(self, repo: str) -> bool:
        """Rollback single repository."""
        # Implementation would revert to previous workflow versions
        # For now, just log the rollback
        return True

    def save_deployment_log(self):
        """Save deployment log to file."""
        log_file = Path(f"automation/deployment/logs/{self.deployment_id}.json")
        log_file.parent.mkdir(parents=True, exist_ok=True)

        with open(log_file, "w") as f:
            json.dump(
                {
                    "deployment_id": self.deployment_id,
                    "environment": self.environment,
                    "timestamp": datetime.now().isoformat(),
                    "deployments": self.deployment_log,
                },
                f,
                indent=2,
            )

        print(f"\nüìù Deployment log saved: {log_file}")


def main():
    """Main deployment orchestration."""
    parser = argparse.ArgumentParser(description="Deploy workflow automation")
    parser.add_argument(
        "--env",
        choices=["staging", "production"],
        required=True,
        help="Target environment",
    )
    parser.add_argument("--month", type=int, choices=[1, 2, 3], required=True, help="Month to deploy")
    parser.add_argument("--canary-repos", type=str, help="Comma-separated list of canary repositories")
    parser.add_argument("--rollback", action="store_true", help="Rollback deployment")
    parser.add_argument("--deployment-id", type=str, help="Deployment ID to rollback")

    args = parser.parse_args()

    # Get GitHub token
    github_token = os.getenv("GITHUB_TOKEN")
    if not github_token:
        print("‚ùå GITHUB_TOKEN environment variable not set!")
        sys.exit(1)

    # Initialize orchestrator
    orchestrator = DeploymentOrchestrator(args.env, github_token)

    # Handle rollback
    if args.rollback:
        if not args.deployment_id:
            print("‚ùå --deployment-id required for rollback")
            sys.exit(1)
        orchestrator.rollback()
        sys.exit(0)

    # Validate environment
    if not orchestrator.validate_environment():
        sys.exit(1)

    # Parse canary repositories
    canary_repos = None
    if args.canary_repos:
        canary_repos = [r.strip() for r in args.canary_repos.split(",")]

    # Execute deployment
    success = orchestrator.deploy_workflows(args.month, canary_repos)

    # Save deployment log
    orchestrator.save_deployment_log()

    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
